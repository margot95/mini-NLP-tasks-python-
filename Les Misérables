from urllib import request 
url = "https://www.gutenberg.org/files/135/135-0.txt"
#import Les Mis√©rables book, english translation
response = request.urlopen(url)
raw = response.read().decode('utf8')

import nltk
from nltk import sent_tokenize
from nltk import word_tokenize


#cutting off the text that is before the preface

text = []
preface_index = int(raw.index('PREFACE'))
text = raw[preface_index:] 
    

#tokenizing by hand
sentences = sent_tokenize(text)
raw_ = raw.split(".")
sentences = len(raw_)
raw_ = raw.split("!")
sentences = len(raw_) + sentences
raw_ = raw.split("?")
sentences = len(raw_) + sentences
#If we count '.','?' and '!', we find that there are 36998 sentences in this text.
sentences2 = nltk.sent_tokenize(raw)
#whereas with the nltk tokenizer, we count 30079 sentences in the text.
words = word_tokenize(raw)
#682035 words in the file
#in average, a sentence contains 18.43 words
round(len(words)/sentences,2)


#counting occurrences of I
sentences_I = 0
for i in sentences :
    if "I " in i :
        sentences_I += 1     

#counting sentences that start with "I"
count_sentences_I_begin = 0
for i in sentences :
    if i.startswith("I "):
        count_sentences_I_begin += 1 



#displaying a parse tree (with POS tags for each word) for one sentence in the text
from nltk.corpus import treebank
print(sentences[16])
tokens = nltk.word_tokenize(sentences[16])
print(tokens)
tagged = nltk.pos_tag(tokens)
entities = nltk.chunk.ne_chunk(tagged)
entities.draw() 

